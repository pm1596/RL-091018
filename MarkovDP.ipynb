{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MarkovDP.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Tq5lmBbBBDBo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "from operator import add\n",
        "MIN_DELTA = 1e-4\n",
        "\n",
        "class GridMarkovDP(object):\n",
        "    def __init__(self, metadata):\n",
        "        self.width = metadata['width']\n",
        "        self.height = metadata['height']\n",
        "        self.initial_value = metadata['initial_value']\n",
        "        self.obstacles = metadata['obstacles']\n",
        "        self.living_cost = metadata['living_cost']\n",
        "\n",
        "        self.discount = metadata['discount']\n",
        "        self.transition_distribution = metadata['transition_distribution']\n",
        "        self.rewards = {tuple(terminal['state']) : terminal['reward'] for terminal in metadata['terminals']}\n",
        "        self.terminals = list(self.rewards.keys())\n",
        "\n",
        "        self._init_grid()\n",
        "\n",
        "        # enumerate state space\n",
        "        self.states = set()\n",
        "        for row in range(self.height):\n",
        "            for col in range(self.width):\n",
        "                if self.grid[row][col] is not None:\n",
        "                    self.states.add((row, col))\n",
        "        \n",
        "        # move one tile at a time\n",
        "        self.actions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
        "        self.num_actions = len(self.actions)\n",
        "\n",
        "        # initialize values and policy\n",
        "        self.policy = {}\n",
        "        self.values = {}\n",
        "        for state in self.states:\n",
        "            self.values[state] = self.initial_value\n",
        "            self.policy[state] = random.choice(self.actions)\n",
        "\n",
        "    def R(self, state):\n",
        "        if state in self.terminals:\n",
        "            return self.rewards[state]\n",
        "        else:\n",
        "            # living cost\n",
        "            return self.living_cost\n",
        "          \n",
        "    def _init_grid(self):\n",
        "        self.grid = [[self.initial_value for col in range(self.width)] for row in range(self.height)]\n",
        "        # apply obstacles\n",
        "        for obstacle in self.obstacles:\n",
        "            self.grid[obstacle[0]][obstacle[1]] = None\n",
        "            \n",
        "    def _move_forward(self, state, action):\n",
        "        new_state = tuple(map(add, state, action))\n",
        "        return new_state if new_state in self.states else state\n",
        "\n",
        "    def _move_backward(self, state, action):\n",
        "        new_action = self.actions[(self.actions.index(action) + 2) % self.num_actions]\n",
        "        new_state = tuple(map(add, state, new_action))\n",
        "        return new_state if new_state in self.states else state\n",
        "\n",
        "    def _move_left(self, state, action):\n",
        "        new_action = self.actions[(self.actions.index(action) - 1) % self.num_actions]\n",
        "        new_state = tuple(map(add, state, new_action))\n",
        "        return new_state if new_state in self.states else state\n",
        "\n",
        "    def _move_right(self, state, action):\n",
        "        new_action = self.actions[(self.actions.index(action) + 1) % self.num_actions]\n",
        "        new_state = tuple(map(add, state, new_action))\n",
        "        return new_state if new_state in self.states else state \n",
        "      \n",
        "    def allowed_actions(self,state):\n",
        "      if state in self.terminals:\n",
        "        return[None]\n",
        "      else:\n",
        "        return self.actions\n",
        "      \n",
        "     \n",
        "    def next_state_distribution(self, state, action):\n",
        "        if action == None:\n",
        "            return [(0.0, state)]\n",
        "        else:\n",
        "            return [(self.transition_distribution['forward'], self._move_forward(state, action)),\n",
        "                    (self.transition_distribution['left'], self._move_left(state, action)),\n",
        "                    (self.transition_distribution['right'], self._move_right(state, action)),\n",
        "                    (self.transition_distribution['backward'], self._move_backward(state, action))]\n",
        "          \n",
        "    \n",
        "    def update_values(self,values):\n",
        "      self.values=values\n",
        "      \n",
        "      \n",
        "    def update_policy(self,policy):\n",
        "      self.policy=policy\n",
        "      \n",
        "      \n",
        "      \n",
        "    def clear(self):\n",
        "        self._init_grid()\n",
        "        for state in self.states:\n",
        "            self.values[state] = self.initial_value\n",
        "            self.policy[state] = random.choice(self.actions)\n",
        "            \n",
        "            \n",
        "    \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}